{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21721a-62f0-4ad8-9c56-6ab06a4c02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AdvancedBTCPredictor:\n",
    "    def __init__(self, symbol=\"BTC-USD\", period=\"365d\"):\n",
    "        self.symbol = symbol\n",
    "        self.period = period\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_selector = None\n",
    "        self.models = {}\n",
    "        self.ensemble_model = None\n",
    "        self.lstm_model = None\n",
    "        \n",
    "    def download_data(self):\n",
    "        \"\"\"Download Bitcoin data with extended history for better patterns\"\"\"\n",
    "        print(\"ðŸ“¥ Downloading Bitcoin data...\")\n",
    "        self.df = yf.download(self.symbol, period=self.period, interval='1d')\n",
    "        self.df = self.df.dropna()\n",
    "        print(f\"âœ… Downloaded {len(self.df)} days of data\")\n",
    "        return self.df\n",
    "    \n",
    "    def create_advanced_features(self, df):\n",
    "        \"\"\"Create comprehensive technical indicators and features\"\"\"\n",
    "        print(\"ðŸ”§ Creating advanced technical features...\")\n",
    "        \n",
    "        # Price-based features\n",
    "        df['Price_Change'] = df['Close'].pct_change()\n",
    "        df['Price_Change_2d'] = df['Close'].pct_change(periods=2)\n",
    "        df['Price_Change_3d'] = df['Close'].pct_change(periods=3)\n",
    "        df['Price_Change_7d'] = df['Close'].pct_change(periods=7)\n",
    "        \n",
    "        # Volume features\n",
    "        df['Volume_Change'] = df['Volume'].pct_change()\n",
    "        df['Volume_MA_5'] = df['Volume'].rolling(5).mean()\n",
    "        df['Volume_MA_20'] = df['Volume'].rolling(20).mean()\n",
    "        df['Volume_Ratio'] = df['Volume'] / df['Volume_MA_20']\n",
    "        \n",
    "        # Moving averages and trends\n",
    "        for period in [5, 10, 20, 50, 100, 200]:\n",
    "            df[f'MA_{period}'] = df['Close'].rolling(period).mean()\n",
    "            df[f'MA_{period}_ratio'] = df['Close'] / df[f'MA_{period}']\n",
    "        \n",
    "        # Exponential moving averages\n",
    "        for period in [12, 26, 50]:\n",
    "            df[f'EMA_{period}'] = df['Close'].ewm(span=period).mean()\n",
    "            df[f'EMA_{period}_ratio'] = df['Close'] / df[f'EMA_{period}']\n",
    "        \n",
    "        # Technical indicators using TA library\n",
    "        # RSI (Relative Strength Index)\n",
    "        df['RSI_14'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()\n",
    "        df['RSI_30'] = ta.momentum.RSIIndicator(df['Close'], window=30).rsi()\n",
    "        \n",
    "        # MACD\n",
    "        macd_indicator = ta.trend.MACD(df['Close'])\n",
    "        df['MACD'] = macd_indicator.macd()\n",
    "        df['MACD_signal'] = macd_indicator.macd_signal()\n",
    "        df['MACD_histogram'] = macd_indicator.macd_diff()\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        bb_indicator = ta.volatility.BollingerBands(df['Close'], window=20, window_dev=2)\n",
    "        df['BB_upper'] = bb_indicator.bollinger_hband()\n",
    "        df['BB_lower'] = bb_indicator.bollinger_lband()\n",
    "        df['BB_middle'] = bb_indicator.bollinger_mavg()\n",
    "        df['BB_width'] = (df['BB_upper'] - df['BB_lower']) / df['BB_middle']\n",
    "        df['BB_position'] = (df['Close'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])\n",
    "        \n",
    "        # Stochastic Oscillator\n",
    "        stoch = ta.momentum.StochasticOscillator(df['High'], df['Low'], df['Close'])\n",
    "        df['Stoch_K'] = stoch.stoch()\n",
    "        df['Stoch_D'] = stoch.stoch_signal()\n",
    "        \n",
    "        # Average True Range (ATR)\n",
    "        df['ATR'] = ta.volatility.AverageTrueRange(df['High'], df['Low'], df['Close']).average_true_range()\n",
    "        \n",
    "        # Williams %R\n",
    "        df['Williams_R'] = ta.momentum.WilliamsRIndicator(df['High'], df['Low'], df['Close']).williams_r()\n",
    "        \n",
    "        # Commodity Channel Index (CCI)\n",
    "        df['CCI'] = ta.trend.CCIIndicator(df['High'], df['Low'], df['Close']).cci()\n",
    "        \n",
    "        # Money Flow Index\n",
    "        df['MFI'] = ta.volume.MFIIndicator(df['High'], df['Low'], df['Close'], df['Volume']).money_flow_index()\n",
    "        \n",
    "        # Rate of Change\n",
    "        df['ROC'] = ta.momentum.ROCIndicator(df['Close']).roc()\n",
    "        \n",
    "        # Volatility features\n",
    "        df['Volatility_5'] = df['Price_Change'].rolling(5).std()\n",
    "        df['Volatility_10'] = df['Price_Change'].rolling(10).std()\n",
    "        df['Volatility_20'] = df['Price_Change'].rolling(20).std()\n",
    "        \n",
    "        # High-Low features\n",
    "        df['HL_ratio'] = df['High'] / df['Low']\n",
    "        df['HL_pct'] = (df['High'] - df['Low']) / df['Close']\n",
    "        \n",
    "        # Gap features\n",
    "        df['Gap'] = (df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1)\n",
    "        df['Gap_filled'] = np.where(\n",
    "            (df['Gap'] > 0) & (df['Low'] <= df['Close'].shift(1)), 1,\n",
    "            np.where((df['Gap'] < 0) & (df['High'] >= df['Close'].shift(1)), 1, 0)\n",
    "        )\n",
    "        \n",
    "        # Lagged features (previous days' indicators)\n",
    "        lag_features = ['RSI_14', 'MACD', 'BB_position', 'Volume_Ratio']\n",
    "        for feature in lag_features:\n",
    "            for lag in [1, 2, 3]:\n",
    "                df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "        \n",
    "        # Time-based features\n",
    "        df['Day_of_week'] = df.index.dayofweek\n",
    "        df['Month'] = df.index.month\n",
    "        df['Quarter'] = df.index.quarter\n",
    "        df['Is_month_end'] = df.index.is_month_end.astype(int)\n",
    "        df['Is_quarter_end'] = df.index.is_quarter_end.astype(int)\n",
    "        \n",
    "        # Trend strength\n",
    "        df['Trend_strength'] = abs(df['Close'].rolling(20).apply(\n",
    "            lambda x: np.polyfit(range(len(x)), x, 1)[0]))\n",
    "        \n",
    "        print(f\"âœ… Created {len([col for col in df.columns if col not in ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']])} technical features\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_target_variable(self, df, prediction_horizon=1):\n",
    "        \"\"\"Create target variable: 1 if price goes up, 0 if down\"\"\"\n",
    "        df['Target'] = np.where(df['Close'].shift(-prediction_horizon) > df['Close'], 1, 0)\n",
    "        return df\n",
    "    \n",
    "    def prepare_data(self, prediction_horizon=1):\n",
    "        \"\"\"Complete data preparation pipeline\"\"\"\n",
    "        print(\"ðŸŽ¯ Preparing data for training...\")\n",
    "        \n",
    "        # Download and prepare data\n",
    "        self.download_data()\n",
    "        \n",
    "        # Create features\n",
    "        self.df = self.create_advanced_features(self.df)\n",
    "        \n",
    "        # Create target\n",
    "        self.df = self.create_target_variable(self.df, prediction_horizon)\n",
    "        \n",
    "        # Remove NaN values\n",
    "        self.df = self.df.dropna()\n",
    "        \n",
    "        # Feature columns (exclude OHLCV and target)\n",
    "        feature_cols = [col for col in self.df.columns if col not in \n",
    "                       ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'Target']]\n",
    "        \n",
    "        X = self.df[feature_cols].values\n",
    "        y = self.df['Target'].values\n",
    "        \n",
    "        print(f\"âœ… Prepared {len(feature_cols)} features and {len(X)} samples\")\n",
    "        print(f\"ðŸ“Š Target distribution: {np.bincount(y)}\")\n",
    "        \n",
    "        return X, y, feature_cols\n",
    "    \n",
    "    def feature_selection(self, X, y, k=50):\n",
    "        \"\"\"Select best features using statistical tests\"\"\"\n",
    "        print(f\"ðŸŽ¯ Selecting top {k} features...\")\n",
    "        \n",
    "        self.feature_selector = SelectKBest(f_classif, k=k)\n",
    "        X_selected = self.feature_selector.fit_transform(X, y)\n",
    "        \n",
    "        print(f\"âœ… Selected {X_selected.shape[1]} best features\")\n",
    "        return X_selected\n",
    "    \n",
    "    def create_lstm_features(self, data, sequence_length=60):\n",
    "        \"\"\"Create sequences for LSTM model\"\"\"\n",
    "        X_lstm = []\n",
    "        for i in range(sequence_length, len(data)):\n",
    "            X_lstm.append(data[i-sequence_length:i])\n",
    "        return np.array(X_lstm)\n",
    "    \n",
    "    def build_lstm_model(self, input_shape):\n",
    "        \"\"\"Build advanced LSTM model\"\"\"\n",
    "        model = Sequential([\n",
    "            LSTM(128, return_sequences=True, input_shape=input_shape),\n",
    "            Dropout(0.2),\n",
    "            BatchNormalization(),\n",
    "            \n",
    "            LSTM(64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            BatchNormalization(),\n",
    "            \n",
    "            LSTM(32, return_sequences=False),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            Dense(25, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_models(self, X, y):\n",
    "        \"\"\"Train multiple models and create ensemble\"\"\"\n",
    "        print(\"ðŸš€ Training advanced machine learning models...\")\n",
    "        \n",
    "        # Time series split for validation\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Model configurations\n",
    "        models_config = {\n",
    "            'XGBoost': {\n",
    "                'model': xgb.XGBClassifier(\n",
    "                    n_estimators=300,\n",
    "                    max_depth=6,\n",
    "                    learning_rate=0.1,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                'params': {\n",
    "                    'n_estimators': [200, 300, 400],\n",
    "                    'max_depth': [4, 6, 8],\n",
    "                    'learning_rate': [0.05, 0.1, 0.15]\n",
    "                }\n",
    "            },\n",
    "            'LightGBM': {\n",
    "                'model': lgb.LGBMClassifier(\n",
    "                    n_estimators=300,\n",
    "                    max_depth=6,\n",
    "                    learning_rate=0.1,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                'params': {\n",
    "                    'n_estimators': [200, 300, 400],\n",
    "                    'max_depth': [4, 6, 8],\n",
    "                    'learning_rate': [0.05, 0.1, 0.15]\n",
    "                }\n",
    "            },\n",
    "            'RandomForest': {\n",
    "                'model': RandomForestClassifier(\n",
    "                    n_estimators=200,\n",
    "                    max_depth=10,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200, 300],\n",
    "                    'max_depth': [8, 10, 12],\n",
    "                    'min_samples_split': [2, 5, 10]\n",
    "                }\n",
    "            },\n",
    "            'SVM': {\n",
    "                'model': SVC(\n",
    "                    kernel='rbf',\n",
    "                    probability=True,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                'params': {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "                }\n",
    "            },\n",
    "            'LogisticRegression': {\n",
    "                'model': LogisticRegression(random_state=42),\n",
    "                'params': {\n",
    "                    'C': [0.01, 0.1, 1, 10],\n",
    "                    'penalty': ['l1', 'l2'],\n",
    "                    'solver': ['liblinear', 'saga']\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Train and optimize each model\n",
    "        for name, config in models_config.items():\n",
    "            print(f\"ðŸ”§ Training {name}...\")\n",
    "            \n",
    "            # Grid search for hyperparameter optimization\n",
    "            grid_search = GridSearchCV(\n",
    "                config['model'],\n",
    "                config['params'],\n",
    "                cv=tscv,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_scaled, y)\n",
    "            self.models[name] = grid_search.best_estimator_\n",
    "            \n",
    "            print(f\"âœ… {name} best accuracy: {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        # Create ensemble model\n",
    "        ensemble_models = [(name, model) for name, model in self.models.items()]\n",
    "        self.ensemble_model = VotingClassifier(\n",
    "            estimators=ensemble_models,\n",
    "            voting='soft'\n",
    "        )\n",
    "        self.ensemble_model.fit(X_scaled, y)\n",
    "        \n",
    "        # Train LSTM model\n",
    "        print(\"ðŸ§  Training LSTM model...\")\n",
    "        sequence_length = 60\n",
    "        \n",
    "        if len(X_scaled) > sequence_length:\n",
    "            X_lstm = self.create_lstm_features(X_scaled, sequence_length)\n",
    "            y_lstm = y[sequence_length:]\n",
    "            \n",
    "            # Split for LSTM\n",
    "            split_idx = int(0.8 * len(X_lstm))\n",
    "            X_lstm_train, X_lstm_val = X_lstm[:split_idx], X_lstm[split_idx:]\n",
    "            y_lstm_train, y_lstm_val = y_lstm[:split_idx], y_lstm[split_idx:]\n",
    "            \n",
    "            # Build and train LSTM\n",
    "            self.lstm_model = self.build_lstm_model((sequence_length, X_scaled.shape[1]))\n",
    "            \n",
    "            callbacks = [\n",
    "                EarlyStopping(patience=10, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "            ]\n",
    "            \n",
    "            history = self.lstm_model.fit(\n",
    "                X_lstm_train, y_lstm_train,\n",
    "                validation_data=(X_lstm_val, y_lstm_val),\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=callbacks,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… LSTM trained successfully\")\n",
    "        \n",
    "        print(\"ðŸŽ‰ All models trained successfully!\")\n",
    "    \n",
    "    def evaluate_models(self, X_test, y_test):\n",
    "        \"\"\"Evaluate all trained models\"\"\"\n",
    "        print(\"\\nðŸ“Š Model Evaluation Results:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Evaluate individual models\n",
    "        for name, model in self.models.items():\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            results[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc_score,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_pred_proba\n",
    "            }\n",
    "            \n",
    "            print(f\"{name:15} | Accuracy: {accuracy:.4f} | AUC: {auc_score:.4f}\")\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        y_pred_ensemble = self.ensemble_model.predict(X_test_scaled)\n",
    "        y_pred_proba_ensemble = self.ensemble_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        ensemble_accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
    "        ensemble_auc = roc_auc_score(y_test, y_pred_proba_ensemble)\n",
    "        \n",
    "        results['Ensemble'] = {\n",
    "            'accuracy': ensemble_accuracy,\n",
    "            'auc': ensemble_auc,\n",
    "            'predictions': y_pred_ensemble,\n",
    "            'probabilities': y_pred_proba_ensemble\n",
    "        }\n",
    "        \n",
    "        print(f\"{'Ensemble':15} | Accuracy: {ensemble_accuracy:.4f} | AUC: {ensemble_auc:.4f}\")\n",
    "        \n",
    "        # Evaluate LSTM if available\n",
    "        if self.lstm_model and len(X_test_scaled) > 60:\n",
    "            X_test_lstm = self.create_lstm_features(X_test_scaled, 60)\n",
    "            y_test_lstm = y_test[60:]\n",
    "            \n",
    "            y_pred_lstm_proba = self.lstm_model.predict(X_test_lstm)\n",
    "            y_pred_lstm = (y_pred_lstm_proba > 0.5).astype(int).flatten()\n",
    "            \n",
    "            lstm_accuracy = accuracy_score(y_test_lstm, y_pred_lstm)\n",
    "            lstm_auc = roc_auc_score(y_test_lstm, y_pred_lstm_proba)\n",
    "            \n",
    "            results['LSTM'] = {\n",
    "                'accuracy': lstm_accuracy,\n",
    "                'auc': lstm_auc,\n",
    "                'predictions': y_pred_lstm,\n",
    "                'probabilities': y_pred_lstm_proba.flatten()\n",
    "            }\n",
    "            \n",
    "            print(f\"{'LSTM':15} | Accuracy: {lstm_accuracy:.4f} | AUC: {lstm_auc:.4f}\")\n",
    "        \n",
    "        # Find best model\n",
    "        best_model = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "        print(f\"\\nðŸ† Best Model: {best_model} (Accuracy: {results[best_model]['accuracy']:.4f})\")\n",
    "        \n",
    "        return results, best_model\n",
    "    \n",
    "    def predict_tomorrow(self):\n",
    "        \"\"\"Predict tomorrow's price direction\"\"\"\n",
    "        print(\"\\nðŸ”® Predicting Tomorrow's Price Direction...\")\n",
    "        \n",
    "        # Get latest features\n",
    "        latest_features = self.df.iloc[-1][self.feature_cols].values.reshape(1, -1)\n",
    "        \n",
    "        if self.feature_selector:\n",
    "            latest_features = self.feature_selector.transform(latest_features)\n",
    "        \n",
    "        latest_features_scaled = self.scaler.transform(latest_features)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        predictions = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            pred_proba = model.predict_proba(latest_features_scaled)[0][1]\n",
    "            pred = int(pred_proba > 0.5)\n",
    "            predictions[name] = {'prediction': pred, 'probability': pred_proba}\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        ensemble_pred_proba = self.ensemble_model.predict_proba(latest_features_scaled)[0][1]\n",
    "        ensemble_pred = int(ensemble_pred_proba > 0.5)\n",
    "        predictions['Ensemble'] = {'prediction': ensemble_pred, 'probability': ensemble_pred_proba}\n",
    "        \n",
    "        # LSTM prediction if available\n",
    "        if self.lstm_model and len(self.df) > 60:\n",
    "            recent_data = self.scaler.transform(\n",
    "                self.df[self.feature_cols].iloc[-60:].values\n",
    "            )\n",
    "            recent_data = recent_data.reshape(1, 60, -1)\n",
    "            \n",
    "            lstm_pred_proba = self.lstm_model.predict(recent_data)[0][0]\n",
    "            lstm_pred = int(lstm_pred_proba > 0.5)\n",
    "            predictions['LSTM'] = {'prediction': lstm_pred, 'probability': lstm_pred_proba}\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nðŸ“ˆ Tomorrow's Predictions:\")\n",
    "        print(\"=\" * 40)\n",
    "        for name, result in predictions.items():\n",
    "            direction = \"ðŸ“ˆ UP\" if result['prediction'] == 1 else \"ðŸ“‰ DOWN\"\n",
    "            confidence = result['probability'] if result['prediction'] == 1 else (1 - result['probability'])\n",
    "            print(f\"{name:15} | {direction} | Confidence: {confidence:.2%}\")\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "        print(\"ðŸš€ Starting Advanced Bitcoin Price Prediction Analysis\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y, feature_cols = self.prepare_data()\n",
    "        self.feature_cols = feature_cols\n",
    "        \n",
    "        # Feature selection\n",
    "        X_selected = self.feature_selection(X, y, k=min(50, len(feature_cols)))\n",
    "        \n",
    "        # Train-test split (time-aware)\n",
    "        split_idx = int(0.8 * len(X_selected))\n",
    "        X_train, X_test = X_selected[:split_idx], X_selected[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        print(f\"ðŸ“Š Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
    "        \n",
    "        # Train models\n",
    "        self.train_models(X_train, y_train)\n",
    "        \n",
    "        # Evaluate models\n",
    "        results, best_model = self.evaluate_models(X_test, y_test)\n",
    "        \n",
    "        # Make tomorrow's prediction\n",
    "        tomorrow_predictions = self.predict_tomorrow()\n",
    "        \n",
    "        return results, best_model, tomorrow_predictions\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize predictor\n",
    "    predictor = AdvancedBTCPredictor(symbol=\"BTC-USD\", period=\"730d\")  # 2 years of data\n",
    "    \n",
    "    # Run complete analysis\n",
    "    results, best_model, tomorrow_predictions = predictor.run_complete_analysis()\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Summary:\")\n",
    "    print(f\"Best performing model: {best_model}\")\n",
    "    print(f\"Best accuracy achieved: {results[best_model]['accuracy']:.4f}\")\n",
    "    \n",
    "    # Trading strategy evaluation\n",
    "    current_price = predictor.df['Close'].iloc[-1]\n",
    "    print(f\"\\nðŸ’° Current BTC Price: ${current_price:,.2f}\")\n",
    "    \n",
    "    ensemble_prediction = tomorrow_predictions['Ensemble']\n",
    "    direction = \"BUY ðŸ“ˆ\" if ensemble_prediction['prediction'] == 1 else \"SELL ðŸ“‰\"\n",
    "    confidence = ensemble_prediction['probability'] if ensemble_prediction['prediction'] == 1 else (1 - ensemble_prediction['probability'])\n",
    "    \n",
    "    print(f\"ðŸŽ¯ Recommendation: {direction} (Confidence: {confidence:.2%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
