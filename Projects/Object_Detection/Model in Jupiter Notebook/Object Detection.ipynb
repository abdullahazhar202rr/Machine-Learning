{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d28d1d",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e00803",
   "metadata": {},
   "source": [
    "## Using yolo algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e4f641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "yolo_net=cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
    "layer_names=yolo_net.getLayerNames()\n",
    "output_layers=[layer_names[i-1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes=[line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21708241",
   "metadata": {},
   "source": [
    "## Step 1: Load and preprocess the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75ea38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image=cv2.imread(image_path)\n",
    "    height,width,channels=image.shape\n",
    "    blob=cv2.dnn.blobFromImage(image,0.00392,(416,416),(0,0,0),True,crop=False) \n",
    "    yolo_net.setInput(blob) \n",
    "    return image,height,width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d754a2",
   "metadata": {},
   "source": [
    "## Step 2: Detect objects using YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a77b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image_path):\n",
    "    image,height,width=preprocess_image(image_path)    \n",
    "    outputs=yolo_net.forward(output_layers)\n",
    "    class_ids=[]\n",
    "    confidences=[]\n",
    "    boxes=[]\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores=detection[5:]\n",
    "            class_id=np.argmax(scores)\n",
    "            confidence=scores[class_id]\n",
    "            if confidence>0.5:\n",
    "                center_x=int(detection[0]*width)\n",
    "                center_y=int(detection[1]*height)\n",
    "                w=int(detection[2]*width)\n",
    "                h=int(detection[3]*height)\n",
    "                x=int(center_x-w/2)\n",
    "                y=int(center_y-h/2)\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    indices=cv2.dnn.NMSBoxes(boxes,confidences,score_threshold=0.5,nms_threshold=0.4)\n",
    "    return image,boxes,confidences,class_ids,indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2ad5d",
   "metadata": {},
   "source": [
    "## Step 3: Draw bounding boxes and labels on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d14927c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(image,boxes,confidences,class_ids,indices):\n",
    "    for i in indices.flatten():\n",
    "        x,y,w,h=boxes[i]\n",
    "        label=str(classes[class_ids[i]])\n",
    "        confidence=str(round(confidences[i],2))      \n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(image,label+\" \"+confidence,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486c502",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfaf4f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpic.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m image,boxes,confidences,class_ids,indices\u001b[38;5;241m=\u001b[39mdetect_objects(image_path)\n\u001b[0;32m      3\u001b[0m image_with_labels\u001b[38;5;241m=\u001b[39mdraw_labels(image,boxes,confidences,class_ids,indices)\n\u001b[0;32m      4\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected Objects\u001b[39m\u001b[38;5;124m\"\u001b[39m,image_with_labels)\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mdetect_objects\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_objects\u001b[39m(image_path):\n\u001b[1;32m----> 2\u001b[0m     image,height,width\u001b[38;5;241m=\u001b[39mpreprocess_image(image_path)    \n\u001b[0;32m      3\u001b[0m     outputs\u001b[38;5;241m=\u001b[39myolo_net\u001b[38;5;241m.\u001b[39mforward(output_layers)\n\u001b[0;32m      4\u001b[0m     class_ids\u001b[38;5;241m=\u001b[39m[]\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path):\n\u001b[0;32m      2\u001b[0m     image\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m----> 3\u001b[0m     height,width,channels\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      4\u001b[0m     blob\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(image,\u001b[38;5;241m0.00392\u001b[39m,(\u001b[38;5;241m416\u001b[39m,\u001b[38;5;241m416\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),\u001b[38;5;28;01mTrue\u001b[39;00m,crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[0;32m      5\u001b[0m     yolo_net\u001b[38;5;241m.\u001b[39msetInput(blob) \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "image_path='pic.jpeg'\n",
    "image,boxes,confidences,class_ids,indices=detect_objects(image_path)\n",
    "image_with_labels=draw_labels(image,boxes,confidences,class_ids,indices)\n",
    "cv2.imshow(\"Detected Objects\",image_with_labels)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a1328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
